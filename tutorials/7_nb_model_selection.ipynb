{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ka20bzp6PcNj"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Humboldt-WI/bads/blob/master/tutorials/7_nb_model_selection.ipynb) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "swSaDjWvNDnY"
   },
   "source": [
    "# Chapter 7 - Regularization and model selection \n",
    "We have learned about \n",
    "\n",
    "The outline of the tutorial is as follows:\n",
    "- Preliminaries\n",
    "- Regularized logistic regression\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries\n",
    "We begin as usual with importing our standard libraries and also our standard modeling data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard Python libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Some configuration of the plots we will create later\n",
    "%matplotlib inline  \n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# Load credit risk data in pre-processed format from GitHub\n",
    "data_url = 'https://raw.githubusercontent.com/Humboldt-WI/bads/master/data/hmeq_modeling.csv' \n",
    "df = pd.read_csv(data_url, index_col=\"index\")\n",
    "\n",
    "# Pretty printing\n",
    "from pprint import pprint\n",
    "\n",
    "# Extract target variable and feature matrix \n",
    "X = df.drop(['BAD'], axis=1) \n",
    "y = df[['BAD']]\n",
    "\n",
    "# Split data into training and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=888)\n",
    "print(\"Remember the shape of our data: \")\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularized logistic regression \n",
    "Regularization is an approach to find a better balance between bias and variance in the **bias-variance trade-off**, and, thereby, reduce the error of a model. Remember that we can show the (generalization) error of a model to be a function to bias and variance. \n",
    "\n",
    "Complex models often show a high variance. Model complexity and bias are closely connected (low complexity -> high bias and vice versa). Introducing bias can reduce error by reducing variance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![bias and variance](https://miro.medium.com/max/1050/1*oO0KYF7Z84nePqfsJ9E0WQ.png)\n",
    "Image source: [Giorgos Papachristoudis: The Bias-Variance Tradeoff](https://towardsdatascience.com/the-bias-variance-tradeoff-8818f41e39e9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we implement this idea, who can we increase bias to reduce variance? The answer depends on the type of model but at least for regression-type models the answer is: add a complexity penalty. \n",
    "\n",
    "In a regression setting, large coefficients are indicators of complex, unstable models. Possible causes include high dimensionality and multicollinearity. The aim of the model is to minimize the magnitude the coefficients have on the model. Therefore, it is included in the loss function. \n",
    "\n",
    "$$ ðœ·â†minâ¡â„’(ðœ·)+ðœ†||(ðœ·)|| $$\n",
    "\n",
    "This penalty produces sparser models, as it forces the coefficients to zero. Furthermore, we also have a new meta-parameter $ðœ†$, which governs the strength of regularization. Simply put, $ðœ†$ embodies our preference for models that fit the training data more accurately (low $ðœ†$) or models that are less complex (high $ðœ†$). It his hard to impossible to tell suitable settings of $ðœ†$ a priori. Thus, we typically tune this *hyperparameter* for each data set. More on hyperparameter tuning later.\n",
    "\n",
    "We have discussed two forms of common regularization for the example of logistic regression. Both forms work by including a measure of coefficient size into the loss function (i.e. the function which the algorithm optimizes) in the form of a penalty. Intuitively, instead of telling the algorithm to build a model that fits well, we now tell it to build a model that fits well *and* keeps the coefficients small by deducting points in relation to the size of coefficients. \n",
    "\n",
    "The difference between the *lasso* and *ridge* penalty is then only whether we subtract the absolute or the squared sum of coefficients. While lasso tends to set coefficients to 0 completely, the ridge penalty reduces the coefficient size more evenly. We will see that \"why not both?\" is also a legitimate suggestion and leads to the *elastic net* penalty.\n",
    "\n",
    "- why bother -> bias variance trade-off\n",
    "- how -> equations of regularized likelihood function and the "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Options for regularizing the logistic regression model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LASSO\n",
    "Equation and brief discussion of pros and cons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge\n",
    "Equation and brief discussion of pros and cons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic net\n",
    "Equation and brief discussion of pros and cons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO Training regularized logistic regression\n",
    "We have looked at a manual implementation of the logistic regression model in [Tutorial 5](https://github.com/Humboldt-WI/bads/blob/master/tutorials/5_nb_supervised_learning.ipynb). When adding a penalty term to the likelihood function for regularizing our model, we also need to adjust model fitting. Specifically, we now have to minimize the regularized likelihood function. We can still use *gradient descent* but have to adjust the computation of the gradient. Going through this process and implementing regularized logistic regression from scratch would be a perfect exercise to further sharpen your data science skills. Have a look at [Tulrose Deori's post] for some inspiration if needed (https://towardsdatascience.com/implement-logistic-regression-with-l2-regularization-from-scratch-in-python-20bd4ee88a59). \n",
    "\n",
    "In this tutorial, we skip the from scratch implementation and move straight to estimating regularized logit models using our beloved `sklearn` library. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark\n",
    "Idea of regularization is to build better models. We often understand better as more accurate. How tell? we need a benchmark, right?\n",
    "- split data into train & test\n",
    "- estimate vanilla logit model\n",
    "- calc test auc and accuracy\n",
    "- also calc test auc/accuracy of a naive model always predicting good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SKlearn regularization\n",
    "- estimate 3 logit regularized models (vanilla, lasso, l2, enet) using sklearn and home credit data\n",
    "- compare model coefficients\n",
    "  - insert a sub-chapter which compares Lasso to Ridge (results are already available, just need discussion)\n",
    "  - We predict that lasse removes variables while Ridge does not\n",
    "  - make sure that we see some zero coefficients in our Lasso model\n",
    "- compare model predictive performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias and variance\n",
    "idea of regularization is to introduce bias to reduce variance. Can we confirm this works?\n",
    "- use all data and run a cross-validation\n",
    "- test whether the variance in predictive performance (auc +accuracy) is later for logit compared to a regularized logit (no need to use all 3 regularized models here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization path\n",
    "We have seen above that LASSO performs feature selection by setting coefficients to zero. A nice feature of regularized linear models is that we can compute the **full regularization path**. This means we can examine the examine the magnitude of coefficient values across different settings of the penalty parameter. The larger the penalty the more emphasize is put on shrinking coefficients, and the less emphasize is put on minimizing the loss. The following codes, which are from the set of [sklearn examples](https://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_coordinate_descent_path.html#sphx-glr-auto-examples-linear-model-plot-lasso-coordinate-descent-path-py), showcase how to produce a graph of the regularization path. This analysis is useful to inform our choice of penalty values for grid-search. However, for larger data sets, computing the regularization path is a costly exercise. If the goal is to learn which features are most valuable, there are cheaper to establish feature importance. We will learn about these in [Tutorial 9](https://github.com/Humboldt-WI/bads/blob/master/tutorials/9_nb_feature_engineering.ipynb). For now, however, let's see how we can calculate the full regularization path using `sklearn` and re-produce the nice picture from one of the lecture slides.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import lasso_path\n",
    "alphas_lasso, coefs_lasso, _ = lasso_path(X, y, fit_intercept=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results based on https://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_coordinate_descent_path.html#sphx-glr-auto-examples-linear-model-plot-lasso-coordinate-descent-path-py\n",
    "from itertools import cycle\n",
    "colors = cycle(['b', 'r', 'g', 'c', 'k'])\n",
    "\n",
    "plt.figure(figsize=[10,8])\n",
    "\n",
    "neg_log_alphas_lasso = -np.log10(alphas_lasso)\n",
    "for coef_l, c in zip(coefs_lasso, colors):\n",
    "    l1 = plt.plot(neg_log_alphas_lasso, coef_l, c=c)\n",
    "\n",
    "plt.xlabel('-Log(alpha)')\n",
    "plt.ylabel('coefficients')\n",
    "plt.title('Lasso regularization paths')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO Overfitting\n",
    "Ultimately, regularization is a way to address one of the key problems in predictive modeling, the problem of overfitting. \n",
    "- discuss results from previous analysis\n",
    "- do we see evidence of overfitting?\n",
    "- Maybe not since using linear models. Let's check out trees\n",
    "**showcase overfitting problem using deep trees**\n",
    "e.g., chart of AUC or accuracy if better on train and test versus tree depth "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO Model selection\n",
    "Analysis of regularization path has illustrated how different values of the penalty lead to different models. Affect on predictive performance can also be expected. \n",
    "- examine for one regularized model how AUC changes with different models\n",
    "\n",
    "## Grid search\n",
    "Lecture introduced *grid-search* as a versatile approach toward model selection aka hyper parameter tuning. Let's revisit the approach\n",
    "- demonstrate tuning manually\n",
    "- split data into training, validation and test\n",
    "- specify some candidate settings for regularization parameter\n",
    "- find best setting on validation data and check how well model predicts on test\n",
    "- compare to logit w/o regularization\n",
    "\n",
    "## Hyperparameter tuning in sklearn\n",
    "- demonstrate how we can use sklearn for tuning\n",
    "- demo should highlight that tuning different models is easy\n",
    "  - can compare different regularizers\n",
    "  - also can add trees and tune hyperparameter like max depth\n",
    "- also mention/demonstrate flexibility in terms of data use\n",
    "  - first replicate above train/validation/test splitting\n",
    "  - then showcase a few other processes like cross-validation and test set\n",
    "  - or repeated CV and test set\n",
    "- since cross-validation is costly, maybe add a short demo of running CV in parallel; skip if too difficult  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (adams)",
   "language": "python",
   "name": "pycharm-feb95198"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
