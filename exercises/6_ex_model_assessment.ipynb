{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uXol0MrgrGLX"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Humboldt-WI/bads/blob/master/exercises/6_ex_model_assessment.ipynb) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Autq7nJ8pGJb"
   },
   "source": [
    "# Exercises for Model Assessment \n",
    "\n",
    "This notebook is based on the [Model Assessment Notebook](https://). \n",
    "This notebook will guide you through related tasks to strengthen your understanding of these concepts & Python programming. Completing this exercise will bring you be yet another step closer to becoming a true data scientist!\n",
    "\n",
    "Before we start, we will undergo the following steps:\n",
    "- import standard libraries and set plotting parameters\n",
    "- import data and define target variable and features\n",
    "- splitting the data (if you are not familiar with this concept please return to the tutorial)\n",
    "- train a logit and tree model\n",
    "\n",
    "At this point, these tasks have become standard practice for us, so we simply provide the codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "UJ-ZuTe9sAmw"
   },
   "outputs": [],
   "source": [
    "# Importing standard libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "\n",
    "# Set parameters for plotting\n",
    "%matplotlib inline  \n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "QTEPtjAZrj65"
   },
   "outputs": [],
   "source": [
    "# Import data\n",
    "data_url = 'https://raw.githubusercontent.com/Humboldt-WI/bads/master/data/hmeq_modeling.csv' \n",
    "df = pd.read_csv(data_url, index_col=\"index\")\n",
    "\n",
    "# Split data into target and features\n",
    "X = df.drop(['BAD'], axis=1) \n",
    "y = df['BAD']\n",
    "\n",
    "# Zero-one encoding of the target\n",
    "df['BAD'] = df['BAD'].astype(int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "iOi4qEAAsZFX"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=888)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Lb9Ujwtlqay",
    "outputId": "d3575613-9c36-4558-ed43-4dcd3c5f23b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='none',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estimate a logit model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logit = LogisticRegression(penalty='none', fit_intercept=True)\n",
    "logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5OAzxQ9olqa9",
    "outputId": "1a72d3f8-be27-423b-85d0-64f78b0ed907"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=5, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estimate a CART tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier(criterion='gini', max_depth=5)\n",
    "tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1JoWJntgtkHh"
   },
   "source": [
    "## Tasks \n",
    "\n",
    "In case you might have forgotten some general model assessment procedures, we will start with some simple tasks to get you back into the topic! \n",
    "\n",
    "1. Create discrete class predictions for the tree and logit model. Save the results for task 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PCSL49mXvh9y"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rRd_EhY1t4tp"
   },
   "source": [
    "2. Create the corresponding confusion matrix and manually compute, for both classifiers, the accuracy, precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bJdHSVDwuS3V"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hc9JN3I-uTDV"
   },
   "source": [
    "Are these results representative for how good the model is? What are the shortfalls of the accuracy measure?\n",
    "___\n",
    "\n",
    "3. Calculate the  class probabilities for both models for class 1. Save the results for task 4.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8I0Hdc7JvPno"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNG18JYZvQHl"
   },
   "source": [
    "4. Calculate the corresponding AUC values for both predictions and plot the ROC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hQFDkYSWvs5T"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O0XzftqIvtBf"
   },
   "source": [
    "How can we interpret this measure? Is it representative?\n",
    "____\n",
    "Let's have a closer look at how the cutoffs influence our final results. \n",
    "\n",
    "5. Calculate the class probabilities and use these to create discrete class predictions for multiple cutoffs. Vary the cutoff from 0 to 1 in step-sizes of 0.01. Save the accuracy results and corresponding cutoffs. Finally, plot these results, with the cutoffs on the x-axis and the accuracy on the y-axis. Which cutoff gave the highest accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "jQ401RR_xD1v"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pW6S4w-60J5K"
   },
   "source": [
    "Examine these results. How does the cutoff influence the prediction? The `some_model.predict() `function uses a 0.5 cutoff. How did this cutoff perform in your calculations? What cutoff would you recommend based on your results?\n",
    "___\n",
    "\n",
    "6. Use the results of your continuous predictions, extract the true and false positive rate using the function `metrics.roc_curve()` from `sklearn`, and plot a ROC curve. Re-using the cutoff that gave the largest accuracy in the previous task 5, identify the corresponding true and false positive rate. Then highlight this point on the ROC curve. Also highlight the point on the ROC curve that corresponds to a cutoff of 0.5. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RiU8j5HQxQRN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NqILyfIU1H5C"
   },
   "source": [
    "7. Manually define a cutoff in which the ratio of predictions of 0s (goods) and 1s (bads) is representative of the ratio of them in the training data. For example, if your good-to-bad ratio in the training set was 3:1, then your discrete class predictions for the test set should also display this ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T0KHfEir1y9x"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8s2MnS5I1zQc"
   },
   "source": [
    "8. Assess your classifier by creating a precision-recall plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_zoNw3SZ2Dq5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hg3hHtVY2D3x"
   },
   "source": [
    "How does this table differ from the ROC curve? Which of them would you use in different situations?\n",
    "___\n",
    "\n",
    "Next we want to find out how the size of the training set can affect our predictions.\n",
    "\n",
    "9. Create a loop in which you train multiple logit models. Vary a parameter `train_set_size` from 0 to 1 in steps of 0.1. In each iteration of the loop, estimate a logit model using `train_set_size` percent of the actual training set, which we created at the beginning of the exercise. Calculate the AUC for our test set for each model and save it in an array. Finally, create a plot of `train_set_size` on the x-axis versus the corresponding test set AUC on the y-axis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SRX4x97_7nd2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SWgNdd2M7oD1"
   },
   "source": [
    "Looking at this plot, do you think logit is sensitive toward the size of the training set?\n",
    "\n",
    "**Optional:** you could also repeat the above task and create a plot for a decision tree model. This would facilitate comparing the 'hunger' for data between logit and trees.\n",
    "___\n",
    "\n",
    "\n",
    "10. Familiarize yourself with the `StratifiedKFold()` function of `sklean`. We want to use this function to create 5 splits. Use the  ` cross_validate()` function to calculate the corresponding average AUC. Compare the results to the ones in task 4.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XwMDSPgF8E6-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5DOXy8gP8GSo"
   },
   "source": [
    "Which model performed better? How do you explain these results? Read up on this function. How does it work and why would you use it?\n",
    "___\n",
    "___\n",
    "\n",
    "Well done!! You have reached the end of this exercise."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "6_ex_model_assessment",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
